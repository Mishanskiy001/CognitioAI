<h1 align="center">CognitioAI</h1>

<h4 align="center">Ассистент для работы с научной литературой</h4>

<p align="center">

• <a href="#о-проекте">О проекте</a>

• <a href="#цель-проекта">Цель проекта</a>

• <a href="#анализ-области">Анализ области</a>

• <a href="#ключевые-особенности">Ключевые особенности</a>

• <a href="#план-реализации">План реализации</a>

• <a href="#технологическая-основа">Технологическая основа</a>

• <a href="#интерфейс-проекта">Интерфейс проекта</a>

• <a href="#использование">Использование</a>

• <a href="#установка-и-запуск">Установка и запуск</a>

• <a href="#перспективы">Перспективы</a>

• <a href="#обратная-связь">Обратная связь</a>

</p>

## О проекте

В современном мире рабочим в научной сфере приходится тщательно изучать и анализировать огромное кол-во письменных научных работ, что отнимает очень много сил и времени. В таких условиях AI-ассистент, способный сжать, обработать и поставить главные тезисы текста, просто необходим.

## Цель проекта

Разработать научного ассистента, который поможет научным сотрудникам более эффективно управлять информацией и сократить время на обработку и анализ научных публикаций.

## Анализ области

### Процесс работы с научной литературой

1. **Поиск релевантных источников**: учёные используют базы данных для поиска статей по ключевым словам или темам.
2. **Отбор статей для изучения**: учёные отбирают статьи на основе их заголовков, аннотаций и ключевых слов, чтобы определить самое важное для их исследования.
3. **Чтение и анализ**: дальше специалисты читают полный текст, анализируют методику, результаты и выводы.
4. **Структурирование информации**: распределение статьи для более быстрого обращения к ней в будущем.
5. **Цитирование и оформление ссылок**: учёные используют библиографические менеджеры для автоматизации создания ссылок и цитат в их публикациях.

### Проблемы при работе с научной литературой

- **Объем информации**: учёные сталкиваются с проблемой “информационной перегрузки”.
- **Неполные данные или плохая структура**: иногда статьи могут быть плохо структурированы.
- **Неэффективные методы поиска**: трудоёмкость в поиске нужных статей.
- **Время на анализ**: исследователи тратят огромное количество времени на чтение и анализ полного текста статей, даже если некоторые из них могут не быть напрямую полезными.
- **Дублирование исследований**: существует риск дублирования исследований или недостатка знаний о существующих решениях.

### Анализ конкурентов

| Scholarcy | LexRank | SummarizeBot |
| :---: | :---: | :---: |
| это веб-приложение, которое автоматически создает краткие резюме научных статей и отчетов. | это алгоритм (написанный библиотекой для Python “sumy”) на основе графов для автоматической суммаризации текстов, который активно используется. | универсальный инструмент, который поддерживает не только суммаризацию научных текстов, но и новостных статей, технической документации и других типов данных. |

Все предоставленные решения (за исключением LexRank) являются проектами, работающими на облачном хранилище. Они ограничиваются лишь сжатием текста и постановкой его главных задач и смыслов. Наше решение способно отвечать на поставленные пользователем вопросы по тексту, что позволяет использовать ассистента в помощи при подготовке условного теоретического материала для лекций.

## Ключевые особенности

Наше решение может помочь научным специалистам не только по отдельным определённым факторам их трудоёмкой работы, а помогаем во всех поставленных нами проблемами в их сфере.

- *Поиск* — наш ассистент упрощает процесс поиска определённых статей по ключевым словам и главной теме.
- *Обработка* — ассистент способен сжимать и суммаризировать текст. Он обрабатывает исходный текст, определяет его формат (PDF, TXT, и др.), сжимает его и выводит тезисы с вопросами по получившемуся тексту.
- *Ответы на вопросы* — ассистент способен ответить на любой вопрос по тексту.

## План реализации

Описание этапов разработки и работы над проектом.

## Технологическая основа

### Инструменты и библиотеки

***Python*** был выбран в качестве основного языка программирования, поскольку он является предпочтительным при работе с нейронными сетями благодаря своей простоте использования и многофункциональности. 

Также для реализации интерфейса использовались ***HTML***, ***JavaScript***, и ***CSS***.

### Библиотеки

- ***Langchain API*** - библиотека, предоставляющая удобные инструменты для локального запуска больших моделей и обработки больших объëмов данных.
- ***Transformers*** - библиотека от компании Hugging Face, которая предоставляет удобные инструменты для загрузки и использования разнообразного количества моделей.
- ***Flask*** - простой в использовании фреймворк для создания веб-приложений на языке Python.

### Модель

В качестве основной тестовой модели использовалась ***<a href="https://www.alibabacloud.com/en/solutions/generative-ai/qwen?_p_lc=1">Tongyi Qwen</a>*** — языковая модель от Академии Дамо предоставленной компанией Alibaba. Она способна понимать 29 языков и имеет большой объем входных данных.

Модель на <a href="https://huggingface.co/Qwen">Hugging Face</a>.

### Устройство системы

- Загрузка файла/текста пользователем.
- Обработка файла для извлечения текста.
- Выбор пользователем, того что необходимо сделать с текстом (суммаризировать или задать вопрос).
- Обработка текста моделью для выбранной задачи.
- Вывод пользователю ответа модели.

## Интерфейс проекта

Сайт состоит из трех страниц.

*На данный момент поиск статей по темам пользователями не внедрен, в ближайшее время это будет исправлено.*

## Использование

Информация о способах использования сервиса.

## Установка и запуск

Чтобы запустить локальную копию, выполните следующие простые шаги. Учтите, что Python должен быть не менее **3.8.1**:

```shell
# Клонируем репозиторий
> git clone https://github.com/pocketgodru/sirius_ai_biocad.git

# Перемещаемся в него
> cd sirius_ai_biocad

# Создаем виртуальную среду
> python -m venv .venv

# Активируем виртуальную среду
> .venv\Scripts\activate.bat

# Устанавливаем список библиотек
> pip install -r requirements.txt
